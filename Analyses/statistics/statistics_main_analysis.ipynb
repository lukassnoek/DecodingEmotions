{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics notebook: Shared States\n",
    "Accompanying the manuscript: Oosterwijk, Snoek, Rotteveel, Barrett, & Scholte. (submitted). \"Shared states: Using MVPA to test neural overlap between self-focused emotion imagery and other-focused emotion understanding.\"\n",
    "\n",
    "Lukas Snoek, February 2016 | lukassnoek@gmail.com <br>\n",
    "https://github.com/lukassnoek/DecodingEmotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for main analysis\n",
    "The code written for the main analysis (i.e. classification analysis of both the self-data and the generalization to the other-data) in contained in scripts hosted at the above Github repository, in the *main* folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import cPickle\n",
    "import os\n",
    "import glob\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from scipy.stats import f_oneway, ttest_rel, pearsonr, t\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "plot_dir = '/home/lukas/Dropbox/PhD_projects/DecodingEmotions_SCAN/Plots'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below transforms 'raw' confusion matrics (in which the numbers indicate the number of trials assigned to a particular class, with the x-axis referring to the predicted class and the y-axis referring to the true class). The metrics precision (also known as Positive Predictive Value), recall (also known as the True Positive Rate), and F1-score (harmonic mean between precision and recall) are supported. In the article, precision-scores are reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_score_confmat(confmat, metric='precision'):\n",
    "    \n",
    "    if metric == 'precision':\n",
    "            return confmat / confmat.sum(axis=0)\n",
    "    elif metric == 'recall':\n",
    "        return confmat / confmat.sum(axis=1)\n",
    "    elif metric == 'F1':\n",
    "        precision = confmat / confmat.sum(axis=0)\n",
    "        recall = confmat / confmat.sum(axis=1)\n",
    "        return 2 * (recall * precision) / (recall + precision)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN ARTICLE: STATISTICS & PLOTS\n",
    "Below, the results from the validation set (as reported in the main article) are computed. The results from the optimization procedure and final analysis on the (final) optimization set are listed in section 2: SUPPLEMENTARY MATERIALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of results from 100,000 iterations analysis\n",
    "self_dir = '/media/lukas/data/DecodingEmotions/Validation_set/glm_zinnen/100000iter_results'\n",
    "other_dir = '/media/lukas/data/DecodingEmotions/Validation_set/glm_HWW/100000iter_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Statistics of self-analysis\n",
    "Below, we load in the subject-specific confusion matrices and convert the 'raw' metrics to more easily interpretable 'precision' scores:\n",
    "\n",
    "$$ precision = \\frac{true\\ positives}{true\\ positives + false\\ positives} $$\n",
    "\n",
    "The resulting ndarray thus contains precision-matrices for each subject, of which the average is plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "self_files = glob.glob(op.join(self_dir, '*.pickle'))\n",
    "s_confmat = np.zeros((len(self_files), 3, 3))\n",
    "for i, f in enumerate(self_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    s_confmat[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "\n",
    "s_confmat[np.isnan(s_confmat)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['Action', 'Interoception', 'Situation']\n",
    "s_av_cm = s_confmat.mean(axis=0)\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.heatmap(s_av_cm, cmap=plt.cm.Greys, annot=True,\n",
    "                 linewidths=0.1, linecolor='grey', vmax=.6, cbar=True, annot_kws={'fontsize': 20})\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize=15)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.xlabel('Predicted class', fontsize=20, labelpad=19)\n",
    "plt.ylabel('Actual class', fontsize=20, labelpad=19)\n",
    "plt.title('Self-analysis', fontsize=25, y=1.03)\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.savefig(op.join(plot_dir, 'self_confmat.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we'll load in the confusion matrices from the permuted main analysis, which is exactly the same as the main analysis, yet with permuted class labels, yielding random models and corresponding confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading in permutation confusion matrices\n",
    "s_perm_dir = '/media/lukas/data/DecodingEmotions/Validation_set/glm_zinnen/permutation_results/'\n",
    "s_dirs = glob.glob(op.join(s_perm_dir, 'perm_*'))\n",
    "n = s_confmat.shape[0]\n",
    "\n",
    "s_perm_mats = np.zeros((len(s_dirs), n, 3, 3))\n",
    "\n",
    "for i, d in enumerate(s_dirs):\n",
    "    mats = glob.glob(op.join(d, '*confmat.npy'))\n",
    "    \n",
    "    for ii, m in enumerate(mats):\n",
    "        s_perm_mats[i, ii, :, :] = compute_score_confmat(np.load(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Significance: p-value = nr of perms above observed score / nr of total perms\n",
    "# see: Nichols, T. E., & Holmes, A. P. (2002). Nonparametric permutation tests for functional neuroimaging: \n",
    "# a primer with examples. Human brain mapping, 15(1), 1-25\n",
    "s_av_perm_mats = s_perm_mats.mean(axis=1)\n",
    "s_p_cm = np.round((s_confmat.mean(axis=0) < s_av_perm_mats).sum(axis=0) / s_av_perm_mats.shape[0], 3)\n",
    "print(s_p_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics of cross-analysis\n",
    "Below, the same procedure as for the self-analysis is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_files = glob.glob(op.join(other_dir, '*.pickle'))\n",
    "o_confmat = np.zeros((len(other_files), 3, 3))\n",
    "for i, f in enumerate(other_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    o_confmat[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "o_confmat[np.isnan(o_confmat)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o_av_cm = o_confmat.mean(axis=0)\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.heatmap(o_av_cm, cmap=plt.cm.Greys, annot=True,\n",
    "                 linewidths=0.1, linecolor='grey', vmax=.6, cbar=True, annot_kws={'fontsize': 20})\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize=15)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.xlabel('Predicted class', fontsize=20, labelpad=19)\n",
    "plt.ylabel('Actual class', fontsize=20, labelpad=19)\n",
    "plt.title('Cross-analysis', fontsize=25, y=1.03)\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.savefig(op.join(plot_dir, 'cross_confmat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o_perm_dir = '/media/lukas/data/DecodingEmotions/Validation_set/glm_HWW/permutation_results/'\n",
    "o_dirs = glob.glob(op.join(o_perm_dir, 'perm_*'))\n",
    "\n",
    "# perm_mats shape = [nr perms, subjects, n_class, n_class]\n",
    "o_perm_mats = np.zeros((len(o_dirs), o_confmat.shape[0], 3, 3))\n",
    "\n",
    "for i, d in enumerate(o_dirs):\n",
    "    mats = glob.glob(op.join(d, '*confmat.npy'))\n",
    "    for ii, m in enumerate(mats):\n",
    "        o_perm_mats[i, ii, :, :] = compute_score_confmat(np.load(m), 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o_av_perm_mats = o_perm_mats.mean(axis=1)\n",
    "o_p_cm = np.round((o_confmat.mean(axis=0) < o_av_perm_mats).sum(axis=0) / o_av_perm_mats.shape[0], 3)\n",
    "print(o_p_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing classification model in voxel-space\n",
    "Here, the process of creating 'voxel plots' in which model parameters (i.e. linear svm weights) are calculated and backprojected. The weights, here, are the average weights across cross-validation iterations, which\n",
    "were subsequently averaged across subjects. Ideally, these mean weight values are normalized by, for example, their standard error, yielding a standard t-value map. However, as the averaged *absolute* weights are biased to be higher than 0, we cannot do a t-test with H<sub>0 </sub>= 0. Therefore, we ran the main analysis again, but now with permuted labels, to keep track of the model weights yielded by random models (i.e. the permuted_scores variable). These permuted weights are subsequently averaged the same way as the 'true' weights. Given this information, we now calculate the t-value map as:\n",
    "\n",
    "$$ t-value = \\frac{(average\\ true\\ weight - average\\ permuted\\ weight)}{standard\\ deviation\\ true\\ weight /(n-1)} $$\n",
    "\n",
    "\n",
    "For more information, check the *skbold* package at Github:\n",
    "https://github.com/lukassnoek/skbold/blob/master/skbold/utils/mvp_utils.py.\n",
    "The code to keep track of svm weights and subsequently how these are averaged across iterations and subjects is contained in the classes *MvpResults* and *MvpAverageResults* respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vox_files = glob.glob('/media/lukas/data/DecodingEmotions/voxel_data/vox_results_mni/*.nii.gz')\n",
    "perm_files = glob.glob('/media/lukas/data/DecodingEmotions/voxel_random/vox_results_mni/*.nii.gz')\n",
    "\n",
    "vox_scores = np.zeros((len(vox_files), 91, 109, 91, 3))\n",
    "perm_scores = np.zeros((len(perm_files), 91, 109, 91, 3))\n",
    "\n",
    "for i, (v, p) in enumerate(zip(vox_files, perm_files)):\n",
    "    perm_scores[i, :, :, :, :] = nib.load(p).get_data()\n",
    "    vox_scores[i, :, :, :, :] = nib.load(v).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skbold.ROIs as roi # allows to import MNI152 brain\n",
    "mni = op.join(op.dirname(roi.__file__), 'MNI152_2mm.nii.gz')\n",
    "affine = nib.load(mni).get_affine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perm_average = np.abs(perm_scores).mean(axis=4)\n",
    "vox_average = np.abs(vox_scores).mean(axis=4)\n",
    "t_permuted = (vox_average.mean(axis=0) - perm_average.mean(axis=0)) / (vox_average.std(axis=0) / np.sqrt(n-1))\n",
    "t_permuted[np.isnan(t_permuted)] = 0\n",
    "t_permuted[np.isinf(t_permuted)] = 0\n",
    "nib.save(nib.Nifti1Image(t_permuted, affine), op.join(plot_dir, 'modelweights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = nib.Nifti1Image(np.ma.array(t_permuted, mask=t_permuted < 0), affine)\n",
    "weightsplot = plot_stat_map(img, display_mode='x', threshold=1.75, cut_coords=(-57, -50, -30, 0, 30, 50, 58),\n",
    "                            vmax=5.5)\n",
    "weightsplot.savefig(op.join(plot_dir, 'weightsplot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, a custom-function from the skbold-package is used to extract ROI-information about the weights-plot, i.e. how many voxels are contained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skbold.postproc import extract_roi_info\n",
    "print(roi.__file__)\n",
    "df = extract_roi_info(op.join(plot_dir, 'modelweights.nii'), stat_threshold=1.75,\n",
    "                 per_cluster=False, roi_type='bilateral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The tables\\* describing, per brain region, the amount of voxels (and max. value, coordinates, etc.) included in the brain maps are computed using the *extract_roi_info()* function in the *skbold* package (module: misc_utils). Brain masks from the Harvard-Oxford Cortical atlas, which are probabilistic masks, were thresholded at 25% to minimize overlap between regions while covering as much as the brain as possible.\n",
    "\n",
    "\\* Supplementary Tables 3-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPLEMENTARY MATERIALS\n",
    "Below, the statistics, plots, and other supporting analyses for the manuscript's supplementary materials are calculated/performed.\n",
    "\n",
    "**Note**: Details about the pilot study in which the stimuli for the self-focused task were developed (supplementary table 1) can be send upon request. Also, no code is available accompanying Supplementary Figure 2 (and its corresponding analyses), because these results were acquired with an old analysis pipeline implemented in MATLAB (and plotted in R)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary figure 1: percentage of trials executed successfully\n",
    "Also lists some code for descriptive statistics mentioned in the main article (e.g. demographics data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some demographics\n",
    "home = '/home/lukas/Dropbox/PhD_projects/DecodingEmotions_SCAN/Behavioral_data'\n",
    "plot_dir = op.join(op.dirname(home), 'Plots')\n",
    "demographics_file = op.join(home, 'demographics.csv')\n",
    "demogr = pd.read_csv(demographics_file, sep=',')\n",
    "\n",
    "m_age = demogr['age'].mean()\n",
    "std_age = demogr['age'].std()\n",
    "number_female = np.sum([g == 'F' for g in demogr['gender']])\n",
    "print('Mean age: %f, std age: %f' % (m_age, std_age))\n",
    "print('Proportion female: %f' % number_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_file = op.join(home, 'validation_behav.csv')\n",
    "val_data = pd.read_csv(validation_file, sep=',')\n",
    "\n",
    "# val_data is in 'wide' format, but for seaborn-style plots, we need a long format\n",
    "vars_to_melt = ['suc_other_act', 'suc_other_int', 'suc_other_sit', 'suc_self_act', 'suc_self_int', 'suc_self_sit']\n",
    "df_long = pd.melt(val_data, id_vars=['sub_name'], value_vars=vars_to_melt)\n",
    "df_long['condition'] = ['self' if 'self' in c else 'other' for c in df_long['variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(121)\n",
    "sns.barplot(x='variable', y='value', data=df_long[df_long['condition']=='self'], palette='Greys')\n",
    "ax1.set_ylabel('% succesful', fontsize=15), ax1.set_xlabel('')\n",
    "ax1.set_xticklabels(['Action', 'Interoception', 'Situation'], fontsize=10)\n",
    "ax1.set_title('SF-task', fontsize=18)\n",
    "ax2 = plt.subplot(122, sharex=ax1, sharey=ax1)\n",
    "sns.barplot(x='variable', y='value', data=df_long[df_long['condition']=='other'], palette='Greys')\n",
    "ax2.set_ylabel(''), ax2.set_xlabel('')\n",
    "ax2.set_xticklabels(['Action', 'Interoception', 'Situation'], fontsize=10)\n",
    "ax2.set_title('OF-task', fontsize=18)\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig(op.join(plot_dir, 'success.png'), dpi=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accompanying inferential statistics\n",
    "Including a one-way ANOVA for testing the overall effect and follow-up pairwise comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = val_data.shape[0]\n",
    "k = 3 # i.e. 3 conditions (act, int, sit)\n",
    "df1 = k - 1\n",
    "df2 = n - k \n",
    "\n",
    "print('F-tests')\n",
    "fval, pval = f_oneway(val_data['suc_self_act'], val_data['suc_self_int'], val_data['suc_self_sit'])\n",
    "print('Self-data: F(%i, %i) = %f, p = %f' % (df1, df2, fval, pval))\n",
    "\n",
    "fval, pval = f_oneway(val_data['suc_other_act'], val_data['suc_other_int'], val_data['suc_other_sit'])\n",
    "print('Other-data: F(%i, %i) = %f, p = %f' % (df1, df2, fval, pval))\n",
    "\n",
    "print('\\nPairwise comparisons')\n",
    "tval_si, pval_si = ttest_rel(val_data['suc_other_sit'], val_data['suc_other_int'])\n",
    "print('Other sit-int: t(%i) = %f, p = %f)' % (n-1, tval_si, pval_si))\n",
    "\n",
    "tval_sa, pval_sa = ttest_rel(val_data['suc_other_sit'], val_data['suc_other_act'])\n",
    "print('Other sit-act: t(%i) = %f, p = %f)' % (n-1, tval_sa, pval_sa))\n",
    "\n",
    "tval_ai, pval_ai = ttest_rel(val_data['suc_other_act'], val_data['suc_other_int'])\n",
    "print('Other act-int: t(%i) = %f, p = %f)' % (n-1, tval_ai, pval_ai))\n",
    "print('\\nDescriptive statistics')\n",
    "\n",
    "descr_stats = pd.DataFrame()\n",
    "descr_stats['mean'] = val_data[['suc_other_act', 'suc_other_int', 'suc_other_sit']].mean()\n",
    "descr_stats['se'] = val_data[['suc_other_act', 'suc_other_int', 'suc_other_sit']].std() / np.sqrt(n)\n",
    "print(descr_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary figure 3: Confusion matrices from optimization-set\n",
    "Is analyzed/computed/visualized the same way as the confusion matrices from the validation-set. Note, however, that no permutation analysis was performed, so the p-values corresponding the confusion matrix cells were calculated using a regular one-sample t-test (against H<sub>0</sub>: 0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Location of results from 100,000 iterations analysis\n",
    "optself_dir = '/media/lukas/data/DecodingEmotions/Optimization_set/glm_zinnen/analysis_results'\n",
    "optother_dir = '/media/lukas/data/DecodingEmotions/Optimization_set/glm_HWW/analysis_results'\n",
    "\n",
    "optself_files = glob.glob(op.join(optself_dir, '*.pickle'))\n",
    "opts_confmat = np.zeros((len(optself_files), 3, 3))\n",
    "for i, f in enumerate(optself_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    opts_confmat[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "\n",
    "opts_confmat[np.isnan(opts_confmat)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['Action', 'Interoception', 'Situation']\n",
    "opts_av_cm = opts_confmat.mean(axis=0)\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.heatmap(opts_av_cm, cmap=plt.cm.Greys, annot=True,\n",
    "                 linewidths=0.1, linecolor='grey', vmax=.6, cbar=True, annot_kws={'fontsize': 20})\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize=15)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.xlabel('Predicted class', fontsize=20, labelpad=19)\n",
    "plt.ylabel('Actual class', fontsize=20, labelpad=19)\n",
    "plt.title('Self-analysis', fontsize=25, y=1.03)\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.savefig(op.join(plot_dir, 'optself_confmat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = opts_confmat.shape[0]\n",
    "tmat_self = (opts_confmat.mean(axis=0) - 0.333) / (opts_confmat.std(axis=0) / np.sqrt(n-1))\n",
    "pmat_self = np.array([stats.t.sf(np.abs(tt), n-1)*2 for tt in tmat_self])\n",
    "print(pmat_self.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optother_files = glob.glob(op.join(optother_dir, '*.pickle'))\n",
    "opto_confmat = np.zeros((len(optother_files), 3, 3))\n",
    "for i, f in enumerate(optother_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    opto_confmat[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "\n",
    "opto_confmat[np.isnan(opto_confmat)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['Action', 'Interoception', 'Situation']\n",
    "opto_av_cm = opto_confmat.mean(axis=0)\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.heatmap(opto_av_cm, cmap=plt.cm.Greys, annot=True,\n",
    "                 linewidths=0.1, linecolor='grey', vmax=.6, cbar=True, annot_kws={'fontsize': 20})\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize=15)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=14)\n",
    "plt.xlabel('Predicted class', fontsize=20, labelpad=19)\n",
    "plt.ylabel('Actual class', fontsize=20, labelpad=19)\n",
    "plt.title('Cross-analysis', fontsize=25, y=1.03)\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.savefig(op.join(plot_dir, 'optother_confmat.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = opto_confmat.shape[0]\n",
    "tmat_other = (opto_confmat.mean(axis=0) - 0.333) / (opto_confmat.std(axis=0) / np.sqrt(n-1))\n",
    "pmat_other = np.array([stats.t.sf(np.abs(tt), n-1)*2 for tt in tmat_other])\n",
    "print(pmat_other.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary figure 4: relation self- and cross-scores & their distribution \n",
    "The plot below was included to show that, while precision scores between the self- and cross-analyses are uncorrelated, the distributions of scores from both analyses seem quite different. More specifically, the self-scores appear normally distributed, while the cross-scores appear to be have two 'peaks' in their distribution. In other words, there might be two groups of subjects: one which is capable of generalization from self to other and one group which is not (around chance level), which seems to be irrespective of their classification performance on the self-focused task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_prec, c_prec = val_data.self_precision, val_data.cross_precision\n",
    "\n",
    "gs = GridSpec(3, 2)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set_style('ticks')\n",
    "plt.subplot(gs[0:2, 0:2])\n",
    "\n",
    "sns.regplot(s_prec, c_prec, color='red')\n",
    "r, p = pearsonr(s_prec, c_prec)\n",
    "plt.text(0.32, 0.6, 'r = %.2f, p = %.3f' % (r, p), fontsize=17)\n",
    "plt.xlabel('Precision self-analysis', fontsize=15)\n",
    "plt.ylabel('Precision cross-analysis', fontsize=15)\n",
    "\n",
    "plt.subplot(gs[2, 0])\n",
    "sns.distplot(s_prec, bins=6)\n",
    "plt.xlabel('Precision self-analysis')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(0.2, 1.2, 0.2))\n",
    "plt.yticks(np.arange(0, 6, 1))\n",
    "\n",
    "plt.subplot(gs[2, 1])\n",
    "sns.distplot(c_prec, bins=6, color='green')\n",
    "plt.xlabel('Precision cross-analysis')\n",
    "plt.xticks(np.arange(0.2, 1.2, 0.2))\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()#pad=3)\n",
    "plt.savefig(op.join(plot_dir, 'self_cross_relation.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary figure 5: precision vs. recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prec_self = np.zeros((len(self_files), 3, 3))\n",
    "recall_self = np.zeros((len(self_files), 3, 3))\n",
    "\n",
    "for i, f in enumerate(self_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    prec_self[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "    recall_self[i, :, :] = compute_score_confmat(tmp, metric='recall')\n",
    "\n",
    "prec_self[np.isnan(prec_self)] = 0\n",
    "recall_self[np.isnan(recall_self)] = 0\n",
    "prec_self, recall_self = prec_self.mean(axis=0), recall_self.mean(axis=0)\n",
    "\n",
    "prec_other = np.zeros((len(other_files), 3, 3))\n",
    "recall_other = np.zeros((len(other_files), 3, 3))\n",
    "\n",
    "for i, f in enumerate(other_files):\n",
    "    tmp = cPickle.load(open(f)).conf_mat\n",
    "    prec_other[i, :, :] = compute_score_confmat(tmp, metric='precision')\n",
    "    recall_other[i, :, :] = compute_score_confmat(tmp, metric='recall')\n",
    "\n",
    "prec_other[np.isnan(prec_other)] = 0\n",
    "recall_other[np.isnan(recall_other)] = 0\n",
    "prec_other, recall_other = prec_other.mean(axis=0), recall_other.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "labels2 = ['A', 'I', 'S']\n",
    "gs2 = GridSpec(2, 2)\n",
    "\n",
    "plt.subplot(gs2[0, 0])\n",
    "sns.heatmap(prec_self, cmap=plt.cm.Greys, annot=True, cbar=False,\n",
    "            linewidths=0.1, linecolor='grey', vmax=.6, annot_kws={'fontsize': 20}, vmin=0.05)\n",
    "plt.xticks(np.arange(3)+0.5, [''] * len(labels2))\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=11)\n",
    "plt.ylabel('Actual class', fontsize=18, labelpad=19)\n",
    "#plt.title('Precision self-analysis', fontsize=18, y=1.05)\n",
    "\n",
    "plt.subplot(gs2[0, 1])\n",
    "sns.heatmap(prec_other, cmap=plt.cm.Greys, annot=True, cbar=False,\n",
    "            linewidths=0.1, linecolor='grey', vmax=.6, annot_kws={'fontsize': 20}, vmin=0.05)\n",
    "plt.xticks(np.arange(3)+0.5, [''] * len(labels2))\n",
    "plt.yticks(np.arange(3)+0.5, [''] * len(labels2))\n",
    "#plt.title('Precision cross-analysis', fontsize=18, y=1.05)\n",
    "\n",
    "plt.subplot(gs2[1, 0])\n",
    "sns.heatmap(recall_self, cmap=plt.cm.Greys, annot=True, cbar=False,\n",
    "            linewidths=0.1, linecolor='grey', vmax=.6, annot_kws={'fontsize': 20}, vmin=0.05)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=11)\n",
    "plt.yticks(np.arange(3)+0.5, labels, fontsize=11)\n",
    "plt.xlabel('Predicted class', fontsize=18, labelpad=19)\n",
    "plt.ylabel('Actual class', fontsize=18, labelpad=19)\n",
    "#plt.title('Recall self-analysis', fontsize=18, y=1.05)\n",
    "\n",
    "plt.subplot(gs2[1, 1])\n",
    "sns.heatmap(recall_other, cmap=plt.cm.Greys, annot=True, cbar=False,\n",
    "            linewidths=0.1, linecolor='grey', vmax=.6, annot_kws={'fontsize': 20}, vmin=0.05)\n",
    "plt.xticks(np.arange(3)+0.5, labels, fontsize=11)\n",
    "plt.yticks(np.arange(3)+0.5, [''] * len(labels2))\n",
    "plt.xlabel('Predicted class', fontsize=18, labelpad=19)\n",
    "#plt.title('Recall cross-analysis', fontsize=18, y=1.05)\n",
    "\n",
    "plt.savefig(op.join(plot_dir, 'precision_recall_plots.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import os.path as op\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from joblib import Parallel, delayed\n",
    "from skbold.utils.mvp_utils import (MvpResults, MvpAverageResults,\n",
    "                                         DataHandler)\n",
    "from skbold.transformers.transformers import *\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_dir = '/media/lukas/data/DecodingEmotions/Validation_set'\n",
    "self_dir = op.join(project_dir, 'glm_zinnen')\n",
    "other_dir = op.join(project_dir, 'glm_HWW')\n",
    "self_paths = glob.glob(op.join(self_dir, 'sub*'))\n",
    "other_paths = glob.glob(op.join(other_dir, 'sub*'))\n",
    "\n",
    "# Parameters\n",
    "zvalue = 2.3\n",
    "\n",
    "scaler = StandardScaler()\n",
    "transformer = MeanEuclidean(cutoff=zvalue, normalize=True)\n",
    "clf = SVC(kernel='linear', probability=True, decision_function_shape='ovr')\n",
    "pipeline = Pipeline([('transformer', transformer),\n",
    "                     ('scaler', scaler),\n",
    "                     ('classifier', clf)])\n",
    "probas = np.zeros((len(self_paths), 90, 3))\n",
    "\n",
    "for i, (self_path, other_path) in enumerate(zip(self_paths, other_paths)):\n",
    "    self_data = DataHandler(identifier='merged', shape='2D').load_separate_sub(self_path)\n",
    "    other_data = DataHandler(identifier='', shape='2D').load_separate_sub(other_path)\n",
    "\n",
    "    y_ovr = label_binarize(other_data.y, classes=[0, 1, 2])\n",
    "    pipeline.fit(self_data.X, self_data.y)\n",
    "    probas[i, :, :] = pipeline.predict_proba(other_data.X)\n",
    "    #print(confusion_matrix(other_data.y, pipeline.predict(other_data.X)))\n",
    "av_probas = probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Credits to scikit-learn:\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "sns.set_style('white')\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "n_classes = 3\n",
    "y_test = y_ovr\n",
    "y_score = av_probas\n",
    "labels = ['Action', 'Interoception', 'Situation']\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i],\n",
    "             label='{0} (area = {1:0.2f})'\n",
    "                   ''.format(labels[i], average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=15)\n",
    "plt.ylabel('Precision', fontsize=15)\n",
    "plt.title('Precision-recall curves for cross-analysis', fontsize=15, y=1.03)\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "#plt.show()\n",
    "plt.savefig(op.join(plot_dir, 'pr_curve.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "pr, rc = np.zeros((50, 3)), np.zeros((50, 3))\n",
    "indices = [np.arange(30), np.arange(30, 60), np.arange(60, 90)]\n",
    "\n",
    "for i,t in enumerate(np.arange(0, 1, 1/50)):\n",
    "    for ii in range(3):\n",
    "        \n",
    "        rc[i, ii] = (av_probas[indices[ii], ii] > t).mean()\n",
    "        total_pred = (av_probas[:, ii] > t).sum()\n",
    "        if total_pred == 0:\n",
    "            pr[i, ii] = (av_probas[indices[ii], ii] > t).sum() / av_probas.shape[1]\n",
    "        else:\n",
    "            pr[i, ii] = (av_probas[indices[ii], ii] > t).sum() / (av_probas[:, ii] > t).sum()\n",
    "        \n",
    "rc[np.isnan(rc)] = 0\n",
    "pr[np.isnan(pr)] = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
